# Data-cleaning-and-vectors-NLP-

# Data cleaning process.

![alt text](https://miro.medium.com/max/1000/1*yWFQiGjlgHUVYeh4ELELyw.jpeg)

1.Removing the stop words

>Tokenizing the sentence and making a function to skip all the stop words in a sentence or a data series

2.Lemmatize the data

>Converting the words from plural to singular.

3.Stemming the data.

>Converting the words into their root form.

4.Removing the number from the data.

>To have better columns when we vectorize

5.Lower casing the words.

>This is optional, genrally this is done so that "WORDS" and "words" are same words!!!.

# Vectorization

I have also performed the vectorization on my dataset, in this case I have used the count vectors.

# Clustering

![alt text](https://th.bing.com/th/id/R.dc08b8a6973475cfe67f0e5f1a5ea9da?rik=dj%2fj2og3ZIyHug&riu=http%3a%2f%2f1.bp.blogspot.com%2f-iDLGs4qFXLA%2fUUJ-II9s4HI%2fAAAAAAAAAFY%2f107VvikcBh0%2fs1600%2f2-variable-clustering.png&ehk=yMkoj5jZI7P2FGND9ZWyBYteGJ5rLpEML%2bhTLC1U74I%3d&risl=&pid=ImgRaw&r=0)

After the vectorization I have divided my data in a number of clusters using K-means clustering. This was just the demonstrate how vectors and cluster work together.

# Thank you